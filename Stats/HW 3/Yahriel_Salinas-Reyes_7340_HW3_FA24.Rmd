---
title: "R Markdown Yahriel Salinas-Reyes HW 3"
author: "Yahriel Salinas-Reyes"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# clean R environment
```{r}
rm(list = ls(all=TRUE))
graphics.off()
shell("cls")
```

```{r, include=FALSE}
library(readxl)
library(ggplot2)
library(here)
library(epiR)
library(MASS)
library(nnet)
library(car)
library(PairedData)
library(pwr)
library(dplyr)
library(FSA) #posthoc

# Births <- read_excel('C:/Users/fxb180003/Dropbox/00-UTD teaching-Dropbox/000_2024_FALL/R_2024/Data_FA2024/Births.xlsx')
# out.width="60%", fig.align = 'left'
```

library(readxl)  
library(ggplot2)  
library(epiR)  
library(MASS)  
library(nnet)  
library(car)  
library(PairedData)  
library(pwr)  
library(dplyr)  
library(FSA) #posthoc  

# Question 1:   
## What is an F-distribution?  
### Q.1.1 Response: The F-distribution is a continuous probability distribution and it is the distribution of the ratio of two independent chi-squared (X^2) variables divided by their respective degrees of freedom, often used for hypothesis testing. It is characterized by two parameters: 
#### 1. df1 (numerator degrees of freedom): associated with the variance of the first sample.
#### 2. df2 (denominator degrees of freedom): associated with the variance of the second sample.
### Generally, the F-distribution is always skewed to the right and has a range of [0, âˆž) where it approaches infinity to the right without , meaning it never crosses the x-axis. The exact shape of the F-distribution depends on the values of df1 and df2.


## In what situations is the F-distribution applied?  
### Q.1.2 Response: Generally, there are 3 scenarios where we can apply the F distribution.
#### 1. ANOVA (Analysis of Variance): It tests whether there is a significant difference between the means of multiple groups. The F-test is used to compare the variability within groups to the variability between groups.
#### 2. Regression Analysis: The F-test is used to determine whether a group of variables in a linear regression model explains a significant portion of the variability in the outcome variable.
#### 3. Comparing Variances: The F-distribution is used to compare the variances of two independent samples. This is the basis of tests like Leveneâ€™s test or Bartlettâ€™s test for homogeneity of variance.
## The R code below visually compares the shapes of the F-distribution for various pairs of degrees of freedom. How do the degrees of freedom influence the shape of the F-distribution?  
### Q.1.3 Response: The degrees of freedom (df1 and df2) play a significant role in determining the shape of the F-distribution.
#### When df1 (numerator degrees of freedom) is small, the distribution is more right-skewed.
#### As df1 increases, the distribution becomes more symmetric and resembles the normal distribution.
#### df2 (denominator degrees of freedom) affects the spread of the distribution. Smaller df2 values result in a wider, more spread-out distribution with a heavier right tail. As df2 increases, the distribution becomes more concentrated around 1 and less skewed.
#### The R code provided plots F-distributions with different pairs of degrees of freedom. The blue line (df1 = 5, df2 = 2) is more right-skewed, indicating a wider, more spread-out distribution with a heavier tail. As df1 and df2 increase (e.g., the green line with df1 = 30, df2 = 25), the distribution becomes more symmetric and peaks closer to 1.

```{r}
# Generating 100 random numbers from an F-distribution with 5 and 2 degrees of freedom
set.seed(111)
# Set up the x values
x <- seq(0, 5, by = 0.01)
# Calculate the density for different degrees of freedom
y1 <- df(x, df1 = 5, df2 = 2)  # F(5, 2)
y2 <- df(x, df1 = 10, df2 = 5) # F(10, 5)
y3 <- df(x, df1 = 30, df2 = 25) # F(30, 25)

# Plotting the F-distributions
plot(x, y1, type = "l", col = "blue", ylim = c(0, 1.5), 
     ylab = "Density", xlab = "x", 
     main = "F-Distribution with Different Degrees of Freedom")
lines(x, y2, col = "red")
lines(x, y3, col = "green")
# Adding a legend
legend("topright", legend = c("df1=5, df2=2", "df1=10, df2=5", "df1=30, df2=25"), 
       col = c("blue", "red", "green"), lty = 1)
```

# Design a study: 

## Research Question and Introduction:   
Formulate a research question relevant to your field of study. Provide a brief introductory paragraph that includes the context of the case and the units of measurement used.  

## Identify Variables:  
Determine the independent variable (IV) and the dependent variable (DV) in your study.  

## Data Levels:  
Specify the levels of measurement for both the IV and DV.  

## Outcome Measurement:  
Based on your research question, clearly define the outcome you intend to measure.    
# Statistical Analysis:   
Select an appropriate statistical analysis method based on the outcome. Consider options such as a two-sample mean test (parametric or non-parametric), one-way ANOVA (parametric or non-parametric), or correlation (parametric or non-parametric).    

## Hypotheses Formulation:  
Based on the chosen statistical method, formulate the null hypothesis (Ho) and the alternative hypothesis (Ha).    

## Data Generation:  
Assuming your samples are drawn using simple random sampling (SRS), use R code to generate a simulated dataset with a sample size greater than 30.    

## Data Visualization:
Employ appropriate descriptive statistical tools to visualize the data using histograms, scatterplots, or boxplots.  

## Hypothesis Testing:
Use the relevant inferential statistical tool to test your hypotheses.    

## Assumptions Check:  
List the assumptions related to your statistical method and verify that they are met.   

## Report R Output:  
Present the R output, including the test statistic, degrees of freedom (df), confidence interval (CI), and p-value, where applicable.  

## Power Analysis: 
Calculate the statistical power of your study.   

## Conclusion:  
Summarize the findings of your study, ensuring to include the content of your research and the units of measurement.  

### To generage a normally distibuted random sample with sample size more than 30
```{r}

# Set the sample size
sample_size <- 30
# Generate a normally distributed random sample
random_sample <- rnorm(sample_size, mean = 20, sd = 2.5)
# You can adjust the mean and sd parameters to fit your needs. 
```

### To generate pairs of ð‘¥andð‘¦for a correlation study 
```{r}
# Set the sample size
sample_size <- 30
# Generate x values from a normal distribution
set.seed(123)  # Set seed for reproducibility
x <- rnorm(sample_size, mean = 5, sd = 2)
# Generate y values with some noise
y <- 1 + 2 * x + rnorm(sample_size, mean = 0, sd = 1)
# Combine x and y into a data frame and give a name "data"
data <- data.frame(x = x, y = y)
# Display the first few rows of the data
head(data)
plot(x, y)
```

### To generate a non-normally distributed random sample.
```{r}
# Set the sample size
sample_size <- 30 
# Generate an exponentially distributed random sample
set.seed(123)  # Set seed for reproducibility
exp_sample <- rexp(sample_size, rate = 1)  # rate parameter
# Display the first few values
head(exp_sample)
shapiro.test(exp_sample)
```
 
