---
title: "Homework 4 Submission"
rm(list = ls(all=TRUE))
graphics.off()
shell("cls")
knitr::opts_chunk$set(echo = TRUE)
```{r, include=FALSE}
library(readxl)
library(here)
library(epiR)
library(epiR)
library(MASS)
library(nnet)
library(car)
library(PairedData)
library(tidyverse)
library(ggplot2)
library(pwr)
library(FSA)
library(ggpubr)
library(rstatix)
library(datarium)
library(emmeans)
library(sjstats)
library(lme4)
library(lme4)
library(lmerTest)
library(MuMIn)
library(forcats)
library(readxl)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(pwr)
library(ggpubr)
library(rstatix)
library(datarium)
library(emmeans)
library(sjstats)
library(lme4)
library(lmerTest)
library(MuMIn)
library(dplyr)
library(forcats)
library(readxl)
library(tidyverse)
# Question 1
a. Evaluate the null hypothesis that the population proportions of students who drove while drinking are the same in the two calendar years (2010 and 2014).
> For this analysis, we can use the Chi-square test to compare the proportions of students who drove while drinking in both years.
```{r, out.width="60%",}
# Create the contingency table
data1 <- matrix(c(1250, 991, 1387, 1666), nrow = 2, byrow = TRUE)
data1
colnames(data1) <- c("2010", "2014")
rownames(data1) <- c("Yes", "No")
data1 <- as.table(data1)
data1
# Perform the Chi-square test
chi_square_test <- chisq.test(data1)
# Print the result
print(chi_square_test)
```{r, out.width="60%",}
# Create the contingency table
data2 <- matrix(c(1763, 489, 403, 670), nrow = 2, byrow = TRUE)
colnames(data2) <- c("Present", "Absent")
rownames(data2) <- c("Present", "Absent")
data2 <- as.table(data2)
data2
# Perform the Chi-square test
chi_square_test2 <- chisq.test(data2)
# Print the result
print(chi_square_test2)
# Import the dataset
alcohol <- read_excel("alchohol.xls")
# Import the dataset
alcohol <- read_excel("\alchohol.xls")
# Import the dataset
alcohol <- read_excel("\alchohol.xls")
library(readxl)
alcohol <- read_excel("alcohol.xls")
View(alcohol)
# Import the dataset
alcohol <- read_excel("\alchohol.xls")
# Load the necessary library
library(readxl)
# Import the dataset
alcohol <- read_excel("alchohol.xls")
# Import the dataset
alcohol <- read_excel("alcohol.xls")
# Load the necessary library
library(readxl)
# Import the dataset
alcohol_data <- read_excel("alcohol.xls")
# Create a contingency table
contingency_table <- table(alcohol_data$genques, alcohol_data$alcques)
# Perform the Chi-square test
chi_square_result <- chisq.test(contingency_table)
# Display the result
print(chi_square_result)
contingency_table
```
```
# Load the necessary library
library(readxl)
library(ggplot2)
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
# Create a scatter plot
ggplot(ischemic_data, aes(x = time, y = duration)) +
geom_point() +
labs(title = "Scatter Plot of Time to Angina vs Duration of Angina",
x = "Time to Angina (seconds)",
y = "Duration of Angina (seconds)")
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
library(readxl)
ischemic <- read_excel("ischemic.xls")
# Load the necessary library
library(readxl)
library(ggplot2)
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
# Load the necessary library
library(readxls)
library(ggplot2)
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
rm(list = ls(all=TRUE))
graphics.off()
shell("cls")
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(here)
library(epiR)
library(MASS)
library(nnet)
library(car)
library(PairedData)
library(tidyverse)
library(ggplot2)
library(pwr)
library(FSA)
library(ggpubr)
library(rstatix)
library(datarium)
library(emmeans)
library(sjstats)
library(lme4)
library(lmerTest)
library(MuMIn)
library(forcats)
library(readxl)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(pwr)
library(ggpubr)
library(rstatix)
library(datarium)
library(emmeans)
library(sjstats)
library(lme4)
library(lmerTest)
library(MuMIn)
library(dplyr)
library(forcats)
# Create the contingency table
data1 <- matrix(c(1250, 991, 1387, 1666), nrow = 2, byrow = TRUE)
colnames(data1) <- c("2010", "2014")
rownames(data1) <- c("Yes", "No")
data1 <- as.table(data1)
# Perform the Chi-square test
chi_square_test <- chisq.test(data1)
# Print the result
print(chi_square_test)
# Create the contingency table
data2 <- matrix(c(1763, 489, 403, 670), nrow = 2, byrow = TRUE)
colnames(data2) <- c("Present", "Absent")
rownames(data2) <- c("Present", "Absent")
data2 <- as.table(data2)
# Perform the Chi-square test
chi_square_test2 <- chisq.test(data2)
# Print the result
print(chi_square_test2)
# Load the necessary library
library(readxl)
# Import the dataset
alcohol_data <- read_excel("alcohol.xls")
# Create a contingency table
contingency_table <- table(alcohol_data$genques, alcohol_data$alcques)
# Perform the Chi-square test
chi_square_result <- chisq.test(contingency_table)
# Display the result
print(chi_square_result)
# Load the necessary library
library(readxl)
library(ggplot2)
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
# Load the necessary library
library(readxl)
# Import the dataset
alcohol_data <- read_excel("alcohol.xls")
# Create a contingency table
contingency_table <- table(alcohol_data$genques, alcohol_data$alcques)
# Perform the Chi-square test
chi_square_result <- chisq.test(contingency_table)
# Display the result
print(chi_square_result)
```
> Based on the p-value from the Chi-square test result which is less than 0.05, we reject the null hypothesis and we can conclude there is a significant association between the two questionnaires.
# Question 4
a. Create a two-way scatter plot for these data.
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
# Load the necessary library
library(readxl)
library(ggplot2)
# Import the dataset
ischemic_data <- read_excel("ischemic(1).xls")
# Load the necessary library
library(readxl)
library(ggplot2)
# Import the dataset
ischemic_data <- read_excel("ischemic(1).xls")
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
# Create a scatter plot
ggplot(ischemic_data, aes(x = time, y = duration)) +
geom_point() +
labs(title = "Scatter Plot of Time to Angina vs Duration of Angina",
x = "Time to Angina (seconds)",
y = "Duration of Angina (seconds)")
# Perform hypothesis test for correlation
cor_test_result <- cor.test(ischemic$time, ischemic$duration)
> Based on the p-value from the Chi-square test result which is less than 0.05, we reject the null hypothesis and we can conclude there is a significant association between the two questionnaires.
# Import the dataset
ischemic_data <- read_excel("ischemic.xls")
# Create a scatter plot
ggplot(ischemic_data, aes(x = time, y = duration)) +
geom_point() +
labs(title = "Scatter Plot of Time to Angina vs Duration of Angina",
x = "Time to Angina (seconds)",
y = "Duration of Angina (seconds)")
# Create a scatter plot
ggplot(ischemic_data, aes(x = time, y = duration)) +
geom_point() +
labs(title = "Scatter Plot of Time to Angina vs Duration of Angina",
x = "Time to Angina (seconds)",
y = "Duration of Angina (seconds)")
# Create a scatter plot
ggplot(ischemic_data, aes(x = time, y = duration)) +
geom_point() +
labs(title = "Scatter Plot of Time to Angina vs Duration of Angina",
x = "Time to Angina (seconds)",
y = "Duration of Angina (seconds)")
```
> We can inspect the scatter plot for a linear trend. Since the points suggest a linear relationship, we can proceed with correlation analysis.
c. In calculating the correlation coefficient, which test will you use, Pearson or Spearman? Why?
> Since both variables are continuous and likely normally distributed, use Pearson's correlation. If not normally distributed, use Spearman.
d. Test the null hypothesis that the population correlation is equal to 0.
```{r, out.width="60%",}
```{r, out.width="60%",}
# Perform hypothesis test for correlation
cor_test_result <- cor.test(ischemic$time, ischemic$duration)
# Print results
cor_test_result
# Perform hypothesis test for correlation
cor_test_result <- cor.test(ischemic_data$time, ischemic_data$duration)
# Print results
cor_test_result
# Import dataset
lowbwt <- read_excel("lowbwt.xls")
```{r, out.width="60%",}
# Import dataset
lowbwt <- read_excel("lowbwt.xls")
# View the dataset
View(lowbwt)
# Conduct Spearman correlation
spearman_result <- cor.test(lowbwt$sbp, lowbwt$apgar5, method="spearman")
# Print results
spearman_result
# Import dataset
water <- read_excel("water.xls")
# View the dataset
View(water)
# Create scatter plot
plot(water$fluoride, water$caries,
main="Scatter Plot of Fluoride vs Dental Caries",
xlab="Fluoride Content (ppm)",
ylab="Number of Caries per 100 Children",
pch=19, col='green')
# Import dataset
water <- read_excel("water.xls")
# View the dataset
View(water)
# Create scatter plot
plot(water$fluoride, water$caries,
main="Scatter Plot of Fluoride vs Dental Caries",
xlab="Fluoride Content (ppm)",
ylab="Number of Caries per 100 Children",
pch=19, col='green')
# Create scatter plot
plot(water$fluoride, water$caries,
main="Scatter Plot of Fluoride vs Dental Caries",
xlab="Fluoride Content (ppm)",
ylab="Number of Caries per 100 Children",
pch=19, col='green')
## B.
# Calculate correlation
fluoride_caries_correlation <- cor(water$fluoride, water$caries)
fluoride_caries_correlation
## C.
# Conduct hypothesis test
correlation_test <- cor.test(water$fluoride, water$caries)
# Print results
correlation_test
# Import dataset
actions <- read_excel("actions.xls")
# Import dataset
actions <- read_excel("actions.xls")
# Import dataset
actions <- read_excel("actions.xls")
# Import dataset
actions <- read_excel("actions.xls")
# View the dataset
View(actions)
# Calculate correlations
correlation_1991_1992 <- cor(actions$rank91, actions$rank92)
correlation_1991_1993 <- cor(actions$rank91, actions$rank93)
correlation_1991_1994 <- cor(actions$rank91, actions$rank94)
correlation_1991_1995 <- cor(actions$rank91, actions$rank95)
# Print results
correlation_1991_1992
correlation_1991_1993
correlation_1991_1994
correlation_1991_1995
## B.
# Conduct hypothesis tests
test_1991_1992 <- cor.test(actions$rank91, actions$rank92)
## B.
# Conduct hypothesis tests
test_1991_1992 <- cor.test(actions$rank91, actions$rank92)
test_1991_1993 <- cor.test(actions$rank91, actions$rank93)
test_1991_1994 <- cor.test(actions$rank91, actions$rank94)
test_1991_1995 <- cor.test(actions$rank91, actions$rank95)
# Print results
test_1991_1992
test_1991_1993
test_1991_1994
# Print results
test_1991_1992
test_1991_1993
test_1991_1994
test_1991_1995
# Print results
correlation_1991_1992
correlation_1991_1993
correlation_1991_1994
correlation_1991_1995
# Question 13
```{r, out.width="60%",}
rm(list = ls(all=TRUE))
graphics.off()
shell("cls")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary library and dataset
library(readxl)
# Load necessary library and dataset
library(readxl)
heart <- read_excel("heart.xls")
# Part a: Fit two simple linear regression models for PDI and MDI
model_13_pdi <- lm(pdi ~ trtment, data = heart)
model_13_mdi <- lm(mdi ~ trtment, data = heart)
# Display the summaries to interpret the results
summary_pdi <- summary(model_13_pdi)
summary_mdi <- summary(model_13_mdi)
# Print summary outputs
print(summary_pdi)
print(summary_mdi)
# Part b: Interpretation for PDI
# Who is more likely to have a higher PDI score?
cat("\nInterpretation for PDI:\n")
if (summary_pdi$coefficients["trtment", "Estimate"] > 0) {
cat("A child assigned to the low-flow bypass group is more likely to have a higher PDI score by",
round(summary_pdi$coefficients["trtment", "Estimate"], 2), "points on average compared to a child in the circulatory arrest group.\n")
} else {
cat("A child assigned to the circulatory arrest group is more likely to have a higher PDI score.\n")
}
# Part c: Check for statistical significance at the 0.05 level
cat("\nStatistical significance for PDI:\n")
if (summary_pdi$coefficients["trtment", "Pr(>|t|)"] < 0.05) {
cat("The treatment group difference in PDI scores is statistically significant (p-value =",
round(summary_pdi$coefficients["trtment", "Pr(>|t|)"], 4), ").\n")
} else {
cat("The treatment group difference in PDI scores is not statistically significant.\n")
}
cat("\nInterpretation for MDI:\n")
if (summary_mdi$coefficients["trtment", "Estimate"] > 0) {
cat("A child assigned to the low-flow bypass group is more likely to have a higher MDI score by",
round(summary_mdi$coefficients["trtment", "Estimate"], 2), "points on average compared to a child in the circulatory arrest group.\n")
} else {
cat("A child assigned to the circulatory arrest group is more likely to have a higher MDI score.\n")
}
cat("\nStatistical significance for MDI:\n")
if (summary_mdi$coefficients["trtment", "Pr(>|t|)"] < 0.05) {
cat("The treatment group difference in MDI scores is statistically significant (p-value =",
round(summary_mdi$coefficients["trtment", "Pr(>|t|)"], 4), ").\n")
} else {
cat("The treatment group difference in MDI scores is not statistically significant.\n")
}
# Load necessary library and dataset
detroit <- read_excel("detroit.xls")
# Part a: Fit a multiple linear regression model with homicide as the dependent variable
lm_homicide <- lm(homicide ~ register + police + unemp + weekly, data = detroit)
# Display the summary of the model
summary_homicide <- summary(lm_homicide)
print(summary_homicide)
# Part b: Identify significant variables
cat("\nSignificant variables in the model:\n")
significance_threshold <- 0.05
significant_vars <- summary_homicide$coefficients[, "Pr(>|t|)"] < significance_threshold
print(names(summary_homicide$coefficients)[significant_vars])
# Part c: Model selection (explanation added)
cat("\nExplanation for the best model:\n")
cat("The best model includes all four variables since the overall p-value is significant (p =",
round(summary_homicide$fstatistic[3], 5), ") and R-squared =",
round(summary_homicide$r.squared, 4), "indicating a high proportion of variance explained.\n")
# Part d: Coefficients explanation
cat("\nCoefficients explanation:\n")
cat("Intercept (b0):", round(summary_homicide$coefficients["(Intercept)", "Estimate"], 2), "- Baseline homicide rate.\n")
cat("b1 (register):", round(summary_homicide$coefficients["register", "Estimate"], 4), "- Increase in homicide rate per additional 100,000 handgun registrations.\n")
cat("b2 (police):", round(summary_homicide$coefficients["police", "Estimate"], 4), "- Change in homicide rate per additional 100,000 police officers.\n")
cat("b3 (unemp):", round(summary_homicide$coefficients["unemp", "Estimate"], 4), "- Change in homicide rate per 1% increase in unemployment.\n")
cat("b4 (weekly):", round(summary_homicide$coefficients["weekly", "Estimate"], 4), "- Change in homicide rate per increase in average weekly earnings.\n")
# Part e: R-squared explanation
cat("\nR-squared explanation:\n")
cat("The R-squared value is", round(summary_homicide$r.squared, 4),
"which indicates that", round(summary_homicide$r.squared * 100, 2),
"% of the variance in the homicide rate is explained by the model.\n")
# Part d: Coefficients explanation
cat("\nCoefficients explanation:\n")
cat("Intercept (b0):", round(summary_homicide$coefficients["(Intercept)", "Estimate"], 2), "- Baseline homicide rate.\n")
# Load necessary library and dataset
detroit <- read_excel("detroit.xls")
summary(detroit)
